# poetry install --extras "ui llms-llama-cpp vector-stores-qdrant embeddings-huggingface"
server:
  env_name: ${APP_ENV:local}

llm:
  mode: llamacpp
  # Should be matching the selected model
  max_new_tokens: 4096
  context_window: 8000
  tokenizer: mistralai/Mixtral-8x7B-Instruct-v0.1
  temperature: 0.1      # The temperature of the model. Increasing the temperature will make the model answer more creatively. A value of 0.1 would be more factual. (Default: 0.1)

llamacpp:
  prompt_style: "mistral"
  llm_hf_repo_id: TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF
  llm_hf_model_file: mixtral-8x7b-instruct-v0.1.Q6_K.gguf

embedding:
  mode: huggingface

huggingface:
  embedding_hf_model_name: jinaai/jina-embeddings-v2-base-de

vectorstore:
  database: qdrant

qdrant:
  path: local_data/private_gpt/qdrant